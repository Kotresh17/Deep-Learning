{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KOTRESH_SESSION_9.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"Bzlz0oxh-vE6","colab_type":"text"},"cell_type":"markdown","source":[" <h2>LSTM Recurrent Neural Network for code generation of opencv library in a many to many fashion using time distributed dense layer.</h2> \n"," Recurrent neural networks : From one moment to the next, our brain operates as a function. it accepts inputs from our senses and our thoughts and produces in the form of actions and new thoughts. we see a bear and then think \"bear\". we can model this behaviour with a feed forward neural networks. we can teach a feed forward neural network to think \"bear\" when it is shown an image of a bear. \n"," But our brain is not a one-shot function. It runs repeatedly through time. we see a \"bear\" then think \"run\". Importantly, the very same function that transforms the image of the bear into the thought \"bear\" into the thought \"run\". It is a recurring function, which we can model with a recurrent neural network(RNN).\n"," An RNN is a composition of identical feed forward neural networks, one for each moment, or step in time, which we will refer to as 'RNN cells'. these cells operate on their own output, allowing allowing them to be composed. They can also operate on external input and produce external output. Here is a diagram  of a single RNN cell: \n"," <h2></h2> <img src =\" https://r2rt.com/static/images/NH_SingleRNNcell.png\"> \n"," \n"," The two main problem associated with Recurrent neural network are 1. Information morphing : In ability to keep the memory content for more than a few time steps. 2. Vanishing and Exploding gradients: because, backpropogation through time makes them incredibly deep networks. if the gradients explode, we can't train our model. If they vanish, It's difficult for us to learn long-term dependencies.\n"," \n"," To address these issues Sepp Hochreiter and Jurgen Schmidhuber introduced the Long Short Term Memory in the year 1997."]},{"metadata":{"id":"LDbUAiNjFv0v","colab_type":"text"},"cell_type":"markdown","source":["Long Short Term Memory:\n","The Fundamental principle of LSTM's: To ensure the integrity of our messages in the real world, we write them down. writing is a delta to the current state: it is an act of creation or destruction; the subject itself does not morph when you write on it and other thing is the error gradient on the backward-pass is constant, that can be done by an explicit addition or subtraction, so that each element of the state stays constant without outside interference: \"the unit's activation has to remain constant this will be ensured by using the identity function\". \n","The Fundamental challenge of LSTM's: Uncontrolled and uncordinated writing. particularly at the start of training when writes are completely random, create a chaotic state that leads to bad results and from which it can be difficult to recover. \n","To overcome this challenge, the author decided to using selectivity to control and coordinate writing by keeping our state under control is to be selective in three things: what we write, what we read(because we need to read something to know what to write), and what we forget(because obsolete information is a distraction and should be forgotten). The Selective reading, writing and forgetting involves seperate read, write and forget decisions for each element of the state. we will make these decisions by taking advantage of state-sized read, write and forget vectors with value between 0 and 1specifying the percentage of reading, writing and forgetting that we do for each state element. Note that while it may be more natural to think of reading, writing and forgetting as a binary decisions, we need our decisions to be implented via a differentiable function. the logistic sigmoid is a natural choice since it is differentiable and produces continues values between 0 and 1. we call these read, write and forget vectors \"gates\".  our three gates at time step t is denoted as it, the input gate(for writing), ot, the output gate(for reading) and ft, the forget gate(for remembering). st is our candidate write. and âŠ™ denotes elementwise multiplication. xt is the input information and rnn out is the output of the single cell. the below diagram shows the data flow of the LSTM.     <h2></h2> <img src =\" https://r2rt.com/static/images/NH_PrototypeLSTMCell.png\"> \n","<h2></h2> <img src =\" https://cdn-images-1.medium.com/max/1600/0*HO2RAef8iFyAJ04V.png\"> \n"]},{"metadata":{"id":"0yZ0HAarPEDS","colab_type":"text"},"cell_type":"markdown","source":["Here, the main goal of the LSTM RNN network is to generate a opencv source code for a given seed string frm the opencv source code. here we used many to many  model using TimeDistributedDense layer. TimeDistributedDense layer is used to keep one to one relations on input and output. Assume you have 60 time steps with 100 samples of data which is (60 X 100). and you want use RNN with output of 200. If you dont use TImeDIstributedDense Layer, You'll get 100 X 60 X 200 tensor. so you have the output flattened with each timestep mixed. If you apply TimeDistributedDense , you are going to apply fully connected dense on each time step and get output seperately by timesteps. In this project we have taken the all source code of the opencv and converted that into long text format and then we used that text file to feed that into network model. steps to convert all the source code to text format: step1. clone the opencv repository \"git clone https://github.com/opencv/opencv.git\". step 2: change directory to opencv \"cd opencv\". step 3: run this command by giving destination folder as the argument \"find . -name \"*.[c|h]\" | shuf | xargs cat > opencv.txt\". this is the peocedure to convert all the source code to single text file. then we built LSTM model then we feed that data into it trained with iteratively. once the model is build then we took the piece of the corpus from the large chunk of the data and used that as the seed string to generate the source code. finally we gave the length of code to be generate.     \n","\n","\n"]},{"metadata":{"id":"hZQRyELH_HXs","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#define the necessary libraries\n","from __future__ import print_function\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout\n","from keras.layers import LSTM,TimeDistributed,SimpleRNN\n","from keras.utils.data_utils import get_file\n","import numpy as np\n","from time import sleep\n","import random\n","import sys\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fbNgbL3GPl9b","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":85},"outputId":"c9f7d93e-1275-46b1-c007-9425050ed5eb","executionInfo":{"status":"ok","timestamp":1528651616807,"user_tz":-330,"elapsed":3161,"user":{"displayName":"Kotresh R","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101666869305361549080"}}},"cell_type":"code","source":["#Loading the complete opencv source code data in the form of text file from the google drive\n","\n","path = get_file('opencv.txt', origin=\"https://drive.google.com/drive/u/0/folders/18LEsdM1q3wv3Ri8FsSjYR5xn51nH5aBZ\")\n","\n","text = open(path).read()\n","\n","# this finds the number of words\n","print('corpus length:', len(text))\n","\n","# it sorts the all character in the form of particular order\n","chars = sorted(list(set(text)))\n","print('total chars:', len(chars))\n","\n","char_indices = dict((c, i) for i, c in enumerate(chars))\n","indices_char = dict((i, c) for i, c in enumerate(chars))\n","\n","# split the corpus into sequences of length=maxlen\n","#input is a sequence of 40 chars and target is also a sequence of 40 chars shifted by one position\n","#for eg: if you maxlen=3 and the text corpus is abcdefghi, your input ---> target pairs will be\n","# [a,b,c] --> [b,c,d], [b,c,d]--->[c,d,e]....and so on\n","maxlen = 40\n","step = 1\n","sentences = []\n","next_chars = []\n","for i in range(0, len(text) - maxlen+1, step):\n","    sentences.append(text[i: i + maxlen])\n","    next_chars.append(text[i+1:i +1+ maxlen])\n","    #print('nb sequences:', len(sentences))\n","\n","print('Vectorization...')\n","#it will convert each word into a one hot vector\n","X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n","y = np.zeros((len(sentences),maxlen, len(chars)), dtype=np.bool) # y is also a sequence , or  a seq of 1 hot vectors\n","for i, sentence in enumerate(sentences):\n","    for t, char in enumerate(sentence):\n","        X[i, t, char_indices[char]] = 1\n","\n","for i, sentence in enumerate(next_chars):\n","    for t, char in enumerate(sentence):\n","        y[i, t, char_indices[char]] = 1\n","    \n","\n","print ('vetorization completed')\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["corpus length: 71071\n","total chars: 180\n","Vectorization...\n","vetorization completed\n"],"name":"stdout"}]},{"metadata":{"id":"tuQ-lSEMPl9o","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":51},"outputId":"9ffeac5a-7cfe-427e-c458-e76c104b7abb","executionInfo":{"status":"ok","timestamp":1528651619914,"user_tz":-330,"elapsed":3048,"user":{"displayName":"Kotresh R","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101666869305361549080"}}},"cell_type":"code","source":["# build the model: 2 stacked LSTM\n","print('Build model...')\n","model = Sequential()\n","model.add(LSTM(512, input_shape=(maxlen, len(chars)),return_sequences=True))\n","model.add(LSTM(512, return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(TimeDistributed(Dense(len(chars))))\n","model.add(Activation('softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","\n","print ('model is made')\n","\n","# train the model, output generated text after each iteration"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Build model...\n","model is made\n"],"name":"stdout"}]},{"metadata":{"id":"AU-xrQTQPl9v","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":323},"outputId":"7988aa28-53d6-4f10-ef20-7e76ac1c82e7","executionInfo":{"status":"ok","timestamp":1528651621949,"user_tz":-330,"elapsed":1995,"user":{"displayName":"Kotresh R","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101666869305361549080"}}},"cell_type":"code","source":["print (model.summary())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_11 (LSTM)               (None, 40, 512)           1419264   \n","_________________________________________________________________\n","lstm_12 (LSTM)               (None, 40, 512)           2099200   \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 40, 512)           0         \n","_________________________________________________________________\n","time_distributed_6 (TimeDist (None, 40, 180)           92340     \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 40, 180)           0         \n","=================================================================\n","Total params: 3,610,804\n","Trainable params: 3,610,804\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"metadata":{"id":"4e7uxUGzPl92","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1516},"outputId":"02c5d978-20e0-4abd-f0f5-186bc0b2ebdd","executionInfo":{"status":"ok","timestamp":1528654697478,"user_tz":-330,"elapsed":3072546,"user":{"displayName":"Kotresh R","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101666869305361549080"}}},"cell_type":"code","source":["#at each iteration it does 5 epochs  \n","for iteration in range(1, 6):\n","    print()\n","    print('-' * 50)\n","    print('Iteration', iteration)\n","    history=model.fit(X, y, batch_size=128, nb_epoch=5,verbose=1)\n","    sleep(0.1) # python need some time before fitting the model Reference :https://github.com/keras-team/keras/issues/2110    \n","    # saving models at the following iterations -- uncomment it if you want to save weights and load it later\n","    #if iteration==1 or iteration==3 or iteration==5 or iteration==10 or iteration==20 or iteration==30 or iteration==50 or iteration==60 :\n","    #    model.save_weights('Karpathy_LSTM_weights_'+str(iteration)+'.h5', overwrite=True)\n","    #start_index = random.randint(0, len(text) - maxlen - 1)\n","    #sys.stdout.flush()\n","\n","    print ('loss is')\n","    print (history.history['loss'][0])\n","    print (history)\n","    print()    \n","\n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","--------------------------------------------------\n","Iteration 1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python2.7/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  warnings.warn('The `nb_epoch` argument in `fit` '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/5\n","71032/71032 [==============================] - 124s 2ms/step - loss: 2.5882 - acc: 0.3717\n","Epoch 2/5\n","31104/71032 [============>.................] - ETA: 1:08 - loss: 1.1841 - acc: 0.6955"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 121s 2ms/step - loss: 0.9924 - acc: 0.7425\n","Epoch 3/5\n","50944/71032 [====================>.........] - ETA: 34s - loss: 0.5921 - acc: 0.8429"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 122s 2ms/step - loss: 0.5622 - acc: 0.8507\n","Epoch 4/5\n","60032/71032 [========================>.....] - ETA: 19s - loss: 0.4167 - acc: 0.8882"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.4115 - acc: 0.8895\n","Epoch 5/5\n","64128/71032 [==========================>...] - ETA: 11s - loss: 0.3521 - acc: 0.9038"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.3506 - acc: 0.9042\n","loss is\n","2.588208845988468\n","<keras.callbacks.History object at 0x7f9e2ab0e950>\n","\n","\n","--------------------------------------------------\n","Iteration 2\n","Epoch 1/5\n","37248/71032 [==============>...............] - ETA: 58s - loss: 0.3220 - acc: 0.9107"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.3180 - acc: 0.9114\n","Epoch 2/5\n","53760/71032 [=====================>........] - ETA: 29s - loss: 0.2975 - acc: 0.9159"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.2964 - acc: 0.9161\n","Epoch 3/5\n","61312/71032 [========================>.....] - ETA: 16s - loss: 0.2818 - acc: 0.9192"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.2815 - acc: 0.9192\n","Epoch 4/5\n","64768/71032 [==========================>...] - ETA: 10s - loss: 0.2701 - acc: 0.9216"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.2699 - acc: 0.9216\n","Epoch 5/5\n","66304/71032 [===========================>..] - ETA: 8s - loss: 0.2611 - acc: 0.9234"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 122s 2ms/step - loss: 0.2612 - acc: 0.9234\n","loss is\n","0.31804680701096405\n","<keras.callbacks.History object at 0x7f9e2b95a910>\n","\n","\n","--------------------------------------------------\n","Iteration 3\n","Epoch 1/5\n","37504/71032 [==============>...............] - ETA: 57s - loss: 0.2532 - acc: 0.9252"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.2540 - acc: 0.9248\n","Epoch 2/5\n","53888/71032 [=====================>........] - ETA: 29s - loss: 0.2477 - acc: 0.9263"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.2477 - acc: 0.9262\n","Epoch 3/5\n","61312/71032 [========================>.....] - ETA: 16s - loss: 0.2425 - acc: 0.9273"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.2427 - acc: 0.9271\n","Epoch 4/5\n","64768/71032 [==========================>...] - ETA: 10s - loss: 0.2385 - acc: 0.9279"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.2386 - acc: 0.9279\n","Epoch 5/5\n","66304/71032 [===========================>..] - ETA: 8s - loss: 0.2348 - acc: 0.9287"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.2350 - acc: 0.9287\n","loss is\n","0.2539503556749737\n","<keras.callbacks.History object at 0x7f9e2ab0e950>\n","\n","\n","--------------------------------------------------\n","Iteration 4\n","Epoch 1/5\n","37632/71032 [==============>...............] - ETA: 57s - loss: 0.2306 - acc: 0.9296"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.2319 - acc: 0.9292\n","Epoch 2/5\n","53888/71032 [=====================>........] - ETA: 29s - loss: 0.2287 - acc: 0.9298"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.2292 - acc: 0.9297\n","Epoch 3/5\n","61312/71032 [========================>.....] - ETA: 16s - loss: 0.2267 - acc: 0.9303"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.2269 - acc: 0.9302\n","Epoch 4/5\n","64768/71032 [==========================>...] - ETA: 10s - loss: 0.2246 - acc: 0.9306"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.2248 - acc: 0.9306\n","Epoch 5/5\n","66304/71032 [===========================>..] - ETA: 8s - loss: 0.2225 - acc: 0.9310"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.2227 - acc: 0.9309\n","loss is\n","0.23194461507274433\n","<keras.callbacks.History object at 0x7f9e2b95a910>\n","\n","\n","--------------------------------------------------\n","Iteration 5\n","Epoch 1/5\n","37504/71032 [==============>...............] - ETA: 57s - loss: 0.2200 - acc: 0.9315"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.2211 - acc: 0.9311\n","Epoch 2/5\n","53888/71032 [=====================>........] - ETA: 29s - loss: 0.2189 - acc: 0.9317"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.2195 - acc: 0.9316\n","Epoch 3/5\n","61312/71032 [========================>.....] - ETA: 16s - loss: 0.2179 - acc: 0.9317"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.2182 - acc: 0.9317\n","Epoch 4/5\n","64768/71032 [==========================>...] - ETA: 10s - loss: 0.2168 - acc: 0.9320"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.2169 - acc: 0.9318\n","Epoch 5/5\n","66304/71032 [===========================>..] - ETA: 8s - loss: 0.2155 - acc: 0.9323"],"name":"stdout"},{"output_type":"stream","text":["71032/71032 [==============================] - 123s 2ms/step - loss: 0.2156 - acc: 0.9322\n","loss is\n","0.22109524240424228\n","<keras.callbacks.History object at 0x7f9e2ab0e950>\n","\n"],"name":"stdout"}]},{"metadata":{"id":"85Ru_wj9Pl98","colab_type":"text"},"cell_type":"markdown","source":["#### testing\n","now we will use the trained model to generate code for the seed"]},{"metadata":{"id":"LX_bLJzFPl9-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1632},"outputId":"15b9da22-ef10-4faa-cc79-aeda04718921","executionInfo":{"status":"ok","timestamp":1528654775050,"user_tz":-330,"elapsed":75396,"user":{"displayName":"Kotresh R","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101666869305361549080"}}},"cell_type":"code","source":["seed_string=\"(image_memory_write)(png_structp png_ptr, png_bytep/*const*/ data,\" \n","print (\"seed string -->\", seed_string)\n","print ('The generated text is')\n","sys.stdout.write(seed_string),\n","#x=np.zeros((1, len(seed_string), len(chars)))\n","for i in range(1700):\n","    x=np.zeros((1, len(seed_string[-40:]), len(chars)))\n","    for tt, char in enumerate(seed_string[-40:]):\n","        x[0, tt, char_indices[char]] = 1.\n","    preds = model.predict(x, verbose=0)[0]\n","    next_index=np.argmax(preds[len(seed_string[-40:])-1])\n","      \n","    next_char = indices_char[next_index]\n","    seed_string = seed_string + next_char\n","    sys.stdout.write(next_char)\n","sys.stdout.flush()    \n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["seed string --> (image_memory_write)(png_structp png_ptr, png_bytep/*const*/ data,\n","The generated text is\n","(image_memory_write)(png_structp png_ptr, png_bytep/*const*/ data, .onder-bar {\n","  margin-top: 0;\n","}\n",".dasher-tooltip p span {\n","  display: block;\n","}\n",".card {\n","  margin-bottom: 0;\n","}\n",".one-google {\n","  padding-top: 27px;\n","}\n","#canvas {\n","  -webkit-transition: opacity 0.075s;\n","  -moz-transition: opacity 0.075s;\n","  -ms-transition: opacity 0.075s;\n","  transition: opacity 0.075s;\n","  opacity: 0.01;\n","}\n",".shift-form #canvas {\n","  opacity: 0.99;\n","}\n",".label {\n","  color: #404040;\n","}\n","#account-chooser-link {\n","  -webkit-transition: opacity 0.3s;\n","  -moz-transition: opacity 0.075s;\n","  -ms-transition: opacity 0.075s;\n","  transition: opacity 0.075s;\n","  opacity: 0.01;\n","}\n",".shift-form #canvas {\n","  opacity: 0.99;\n","}\n",".label {\n","  color: #404040;\n","}\n","#account-chooser-link {\n","  -webkit-transition: opacity 0.3s;\n","  -moz-transition: opacity 0.075s;\n","  -ms-transition: opacity 0.075s;\n","  transition: opacity 0.075s;\n","  opacity: 0.01;\n","}\n",".shift-form #canvas {\n","  opacity: "],"name":"stdout"},{"output_type":"stream","text":["0.99;\n","}\n",".label {\n","  color: #404040;\n","}\n","#account-chooser-link {\n","  -webkit-transition: opacity 0.3s;\n","  -moz-transition: opacity 0.075s;\n","  -ms-transition: opacity 0.075s;\n","  transition: opacity 0.075s;\n","  opacity: 0.01;\n","}\n",".shift-form #canvas {\n","  opacity: 0.99;\n","}\n",".label {\n","  color: #404040;\n","}\n","#account-chooser-link {\n","  -webkit-transition: opacity 0.3s;\n","  -moz-transition: opacity 0.075s;\n","  -ms-transition: opacity 0.075s;\n","  transition: opacity 0.075s;\n","  opacity: 0.01;\n","}\n",".shift-form #canvas {\n","  opacity: 0.99;\n","}\n",".label {\n","  color: #404040;\n","}\n","#account-chooser-link {\n","  -webkit-transition: opacity 0.3s;\n","  -moz-transition: opacity 0.075s;\n","  -ms-transition: opacity 0.075s;\n","  transition: opacity 0.075s;\n","  opacity: 0.01;\n","}\n",".shift-form #canvas {\n","  opacity: 0.99;\n","}\n",".label {\n","  color: #404040;\n","}\n","#account-chooser-link {\n","  -webkit-transition: opacity 0.3s;\n","  -moz-transition: "],"name":"stdout"}]},{"metadata":{"id":"riDW_8ClPl-E","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"1c75bd83-3575-4aef-a940-1d4f3cf8befe","executionInfo":{"status":"ok","timestamp":1528654779981,"user_tz":-330,"elapsed":2081,"user":{"displayName":"Kotresh R","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101666869305361549080"}}},"cell_type":"code","source":["len(seed_string)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1766"]},"metadata":{"tags":[]},"execution_count":24}]},{"metadata":{"id":"nv6LGfyPPl-L","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}